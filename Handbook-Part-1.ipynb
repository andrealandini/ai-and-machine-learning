{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddae06f5-c420-4001-924f-3cdf91bb39d5",
   "metadata": {},
   "source": [
    "# Presentation - Final - AI & ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2af1f3-e98d-4b46-ab25-36f359ca1b88",
   "metadata": {},
   "source": [
    "## Introduction & Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ccc77-7e75-4500-85d3-1612ea476bc3",
   "metadata": {},
   "source": [
    "### **Enhancing Econometric QE Models with Machine Learning**\n",
    "\n",
    "The goal of this approach is to improve how we forecast **Quantitative Easing (QE)** decisions by combining **econometric structure** with **machine learning flexibility**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. The Econometric Baseline**\n",
    "\n",
    "Traditionally, we model the probability that the Fed starts QE next quarter as a **logistic regression**:\n",
    "\n",
    "$$\n",
    "P(QE_{t+1}=1 \\mid X_t) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta^\\top X_t)}}.\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "* $QE_{t+1}$ is 1 if the Fed expands its balance sheet by more than $100B next quarter, 0 otherwise.\n",
    "* $X_t$ is a vector of predictors (e.g., Fed balance sheet growth, VIX level, lagged changes).\n",
    "* $\\beta_0, \\beta$ are estimated parameters.\n",
    "\n",
    "This model assumes the relationship between the predictors and QE probability is **linear and additive**.\n",
    "In other words, each variable has a constant effect that does not depend on the level of the others.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Moving Beyond Linearity**\n",
    "\n",
    "Economic behavior is rarely linear — especially monetary policy, which can change sharply when markets reach stress thresholds.\n",
    "To allow for this, we replace the linear term $(\\beta_0 + \\beta^\\top X_t)$ with a **flexible, data-driven function** learned by a machine learning algorithm:\n",
    "\n",
    "$$\n",
    "P(QE_{t+1}=1 \\mid X_t) = f_{\\text{ML}}(X_t).\n",
    "$$\n",
    "\n",
    "Here, $f_{\\text{ML}}$ can be:\n",
    "\n",
    "* A **Random Forest**, which averages many decision trees:\n",
    "  $$\n",
    "  f_{\\text{RF}}(X_t) = \\frac{1}{T}\\sum_{i=1}^{T} h_i(X_t),\n",
    "  $$\n",
    "  capturing patterns like “QE is likely if both volatility and balance sheet growth are high.”\n",
    "* Or an **XGBoost model**, which builds trees sequentially to improve predictions at each step:\n",
    "  $$\n",
    "  f_{\\text{XGB}}(X_t) = \\sum_{m=1}^{M} \\gamma_m h_m(X_t).\n",
    "  $$\n",
    "\n",
    "Both methods can learn **nonlinear thresholds**, **variable interactions**, and **regime changes** that a simple regression cannot.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Why It Matters**\n",
    "\n",
    "This hybrid approach keeps the **probabilistic structure** of econometrics — still predicting $P(QE_{t+1}=1)$ —\n",
    "but allows the data to reveal **how** variables combine in practice, without forcing linearity.\n",
    "\n",
    "So instead of assuming:\n",
    "\n",
    "$$\n",
    "\\text{QE Probability} = \\text{constant} + a \\times \\text{Fed Growth} + b \\times \\text{VIX},\n",
    "$$\n",
    "\n",
    "we estimate:\n",
    "\n",
    "$$\n",
    "\\text{QE Probability} = f_{\\text{ML}}(\\text{Fed Growth}, \\text{VIX}, \\text{Lags}, \\text{Rates}, \\ldots),\n",
    "$$\n",
    "\n",
    "where $f_{\\text{ML}}$ automatically adapts to the shape of the real relationship.\n",
    "\n",
    "---\n",
    "\n",
    "In short:\n",
    "\n",
    "> We extend the classical econometric model by replacing its fixed linear formula with a flexible function learned by machine learning. This allows the QE prediction to depend on complex and realistic patterns in macro-financial data — such as nonlinear interactions, stress thresholds, and changing policy regimes.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to append a small section next that defines **$X_t$** explicitly — describing what each feature represents economically (Fed_Growth, VIX, lags, etc.)?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8630165-3987-48f8-99ee-f9848932c493",
   "metadata": {},
   "source": [
    "## **SLIDE 2 RESEARCH QUESTION**\n",
    "\n",
    "We model the probability that the Federal Reserve will initiate or continue **Quantitative Easing (QE)** in the next quarter as a function of current macro-financial conditions.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Econometric Baseline**\n",
    "\n",
    "$$\n",
    "P(QE_{t+1} = 1 \\mid X_t) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta^\\top X_t)}}\n",
    "$$\n",
    "\n",
    "This is a **logistic regression**, where:\n",
    "\n",
    "* $X_t$ contains indicators such as Fed balance sheet growth, VIX level, and their lags.\n",
    "* $\\beta$ measures how each variable affects QE probability.\n",
    "\n",
    "The model assumes each feature contributes **linearly and independently**, meaning:\n",
    "\n",
    "* An increase in volatility (VIX) always shifts QE probability by the same amount,\n",
    "* regardless of what other variables are doing.\n",
    "\n",
    "This simplicity aids interpretation but limits flexibility — it cannot detect **thresholds** or **interaction effects** between stress and policy variables.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Machine Learning Extension**\n",
    "\n",
    "$$\n",
    "P(QE_{t+1} = 1 \\mid X_t) = f_{\\text{ML}}(X_t)\n",
    "$$\n",
    "\n",
    "Here, $f_{\\text{ML}}$ is a **nonlinear function** learned from data (via Random Forests or XGBoost).\n",
    "Instead of estimating constant coefficients, the model discovers complex patterns such as:\n",
    "\n",
    "* QE becomes more likely when **volatility** and **Fed balance sheet expansion** rise **together**.\n",
    "* A spike in VIX triggers QE only if **previous growth** is slowing.\n",
    "\n",
    "This allows for **state-dependent responses**, where the same variable has different effects depending on the overall market regime.\n",
    "\n",
    "---\n",
    "\n",
    "In short, the econometric model provides structure and interpretability, while the machine learning version introduces flexibility to capture **nonlinear policy reactions** and **joint stress conditions** that better explain QE dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a4d02-4960-4baa-bdcc-1771cca4effd",
   "metadata": {},
   "source": [
    "# Data and Methodolody\n",
    "\n",
    "To model the probability of future **Quantitative Easing (QE)** actions, we build a dataset from macro-financial indicators retrieved from the **Federal Reserve Economic Data (FRED)** database. The focus is on capturing both the **monetary policy stance** of the Federal Reserve and the **financial stress conditions** prevailing in markets.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Monetary Policy Stance – Federal Reserve Securities Holdings**\n",
    "\n",
    "The first series, `WSHOSHO`, measures the **total securities held by the Federal Reserve** on its balance sheet.\n",
    "An increase in these holdings typically reflects **asset purchase programs**—the main mechanism through which QE is implemented.\n",
    "\n",
    "We denote the series as $\\text{Fed\\_Securities}_t$, representing the level of holdings at time $t$.\n",
    "To quantify the **rate of policy expansion**, we compute the quarterly percentage growth:\n",
    "\n",
    "$$\n",
    "\\text{Fed\\_Growth}_t = \\left( \\frac{\\text{Fed\\_Securities}_t}{\\text{Fed\\_Securities}_{t-1}} - 1 \\right) \\times 100\n",
    "$$\n",
    "\n",
    "This variable measures how rapidly the Fed is expanding (or contracting) its securities portfolio.\n",
    "High values of $\\text{Fed\\_Growth}_t$ signal a more **accommodative** stance, often associated with QE initiation or continuation.\n",
    "\n",
    "To capture persistence, we also include its **lagged value**:\n",
    "\n",
    "$$\n",
    "\\text{Fed\\_Growth\\_Lag1}_t = \\text{Fed\\_Growth}_{t-1}\n",
    "$$\n",
    "\n",
    "which represents the previous quarter's monetary expansion rate.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Financial Market Stress – The VIX Index**\n",
    "\n",
    "The second series, `VIXCLS`, represents the **CBOE Volatility Index (VIX)**—a forward-looking measure of expected stock market volatility.\n",
    "Higher VIX values imply greater uncertainty and financial stress, often preceding central bank interventions.\n",
    "\n",
    "We denote this as $\\text{VIX}_t$, and compute both its **change rate** and **stress threshold**:\n",
    "\n",
    "$$\n",
    "\\text{VIX\\_Change}_t = \\left( \\frac{\\text{VIX}_t}{\\text{VIX}_{t-1}} - 1 \\right) \\times 100\n",
    "$$\n",
    "\n",
    "which captures the **percentage increase or decrease in market volatility**, and\n",
    "\n",
    "$$\n",
    "\\text{VIX\\_High}_t =\n",
    "\\begin{cases}\n",
    "1, & \\text{if } \\text{VIX}_t > 30 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where the threshold of 30 marks episodes of **elevated stress** in financial markets.\n",
    "Lagged changes ($\\text{VIX\\_Change\\_Lag1}_t$) are also included to account for **delayed policy reactions**.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Target Variable – Future QE Indicator**\n",
    "\n",
    "The dependent variable represents whether the Fed **expanded its securities holdings by more than \\$100 billion** in the subsequent quarter.\n",
    "This threshold is used to identify significant balance sheet expansions consistent with QE phases.\n",
    "\n",
    "$$\n",
    "QE_{t+1} =\n",
    "\\begin{cases}\n",
    "1, & \\text{if } \\text{Fed\\_Securities}_{t+1} - \\text{Fed\\_Securities}_t > 100 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Thus, the target variable captures **the onset or continuation of QE** in the next quarter, conditional on information available today.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Predictive Feature Set**\n",
    "\n",
    "The feature vector used to predict future QE decisions is:\n",
    "\n",
    "$$\n",
    "X_t = \\{ \\text{Fed\\_Growth}_t, \\text{Fed\\_Growth\\_Lag1}_t, \\text{VIX\\_Level}_t, \\text{VIX\\_Change}_t, \\text{VIX\\_Change\\_Lag1}_t, \\text{VIX\\_High}_t \\}\n",
    "$$\n",
    "\n",
    "This vector combines information about **monetary policy trends** (growth and lags of Fed assets) with **financial stress indicators** (VIX levels, changes, and stress flags).\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Conceptual Framework**\n",
    "\n",
    "The model's goal is to estimate the conditional probability:\n",
    "\n",
    "$$\n",
    "P(QE_{t+1} = 1 \\mid X_t)\n",
    "$$\n",
    "\n",
    "That is, given the current state of financial and policy variables $X_t$, what is the likelihood that the Federal Reserve will engage in quantitative easing in the **next quarter**?\n",
    "\n",
    "This framework provides a bridge between **macroeconomic reasoning** (Fed reaction functions) and **data-driven inference**, serving as the foundation for both the econometric (logistic) and machine learning (random forest, XGBoost) models that follow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b0fd9-7ecf-4b37-baa5-0d43acf7cd31",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "The Random Forest model was introduced to capture **nonlinear relationships** in the prediction of quantitative easing (QE) decisions, which the traditional **logistic regression** model—based on a linear probability function—might overlook.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Logistic Regression (Baseline)\n",
    "\n",
    "The baseline model assumes that the probability of a QE event in the next quarter depends linearly on a set of predictors $X_t$, through the logistic transformation:\n",
    "\n",
    "$$\n",
    "P(QE_{t+1} = 1 \\mid X_t) = \\frac{1}{1 + \\exp(-(\\beta_0 + \\beta^\\top X_t))}.\n",
    "$$\n",
    "\n",
    "Here, $X_t = [\\text{Fed\\_Growth}_t, \\text{Fed\\_Growth\\_Lag1}_t, \\text{VIX\\_Level}_t, \\text{VIX\\_Change}_t, \\text{VIX\\_Change\\_Lag1}_t, \\text{VIX\\_High}_t]$ summarizes both the monetary policy stance and financial market stress.\n",
    "Each coefficient $\\beta_i$ measures the **marginal log-odds impact** of its variable on the likelihood of QE.\n",
    "\n",
    "Empirically, the logistic regression found only **Fed_Growth** significant ($p = 0.03$), implying that higher Fed balance sheet expansion increases the probability of QE continuation. The model achieved an accuracy of 0.73 and AUC around 0.75—adequate, but limited by its linear specification.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Random Forest (Nonlinear Extension)\n",
    "\n",
    "To address this, we applied a **Random Forest (RF)** classifier, which models\n",
    "\n",
    "$$\n",
    "P(QE_{t+1} = 1 \\mid X_t) = f_{\\text{RF}}(X_t),\n",
    "$$\n",
    "\n",
    "where $f_{\\text{RF}}$ is the ensemble average of $B$ decision trees $T_b(X_t)$:\n",
    "\n",
    "$$\n",
    "f_{\\text{RF}}(X_t) = \\frac{1}{B} \\sum_{b=1}^{B} T_b(X_t).\n",
    "$$\n",
    "\n",
    "Each tree partitions the predictor space into regions $R_{b,j}$ and predicts the majority class within each region. By averaging over many trees, Random Forest reduces variance and avoids overfitting—effectively capturing nonlinear interactions such as:\n",
    "\n",
    "* how the Fed's reaction to market volatility ($\\text{VIX}_t$) might depend on current or past balance sheet growth ($\\text{Fed\\_Growth}_t$),\n",
    "* or how persistent volatility shocks affect QE probability differently under high-stress vs. low-stress regimes.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Model Implementation\n",
    "\n",
    "In practice:\n",
    "\n",
    "* The RF model was trained using $500$ trees ($B = 500$),\n",
    "* Two variables were randomly selected at each split to introduce feature diversity,\n",
    "* The model optimized for **classification accuracy** and **out-of-bag (OOB)** error.\n",
    "\n",
    "The out-of-bag error stabilized at **26.6%**, corresponding to an accuracy of approximately **0.77** on the test set—an improvement over the logistic model.\n",
    "The **AUC** increased to **0.85**, showing superior discriminative ability.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Comparative Insights\n",
    "\n",
    "| Model               | Accuracy | AUC   | Key Insights                                                |\n",
    "| ------------------- | -------- | ----- | ----------------------------------------------------------- |\n",
    "| Logistic Regression | 0.73     | ~0.75 | Captures linear effects; only Fed_Growth significant        |\n",
    "| Random Forest       | 0.77     | 0.85  | Captures nonlinearities between policy and market variables |\n",
    "\n",
    "The Random Forest's higher AUC and accuracy suggest that QE decisions are influenced by **interacting and nonlinear dynamics** rather than simple additive effects. For instance, moderate volatility changes may trigger QE only when combined with already high Fed growth or lagged stress indicators.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Interpretation\n",
    "\n",
    "Conceptually, logistic regression assumes a smooth, monotonic response curve, while Random Forest allows the probability surface $f_{\\text{RF}}(X_t)$ to be **piecewise and adaptive** to the data.\n",
    "This flexibility means that the model can approximate:\n",
    "\n",
    "$$\n",
    "P(QE_{t+1} = 1 \\mid X_t) \\approx E[Y \\mid X_t] = \\mathbb{E}_{\\text{data}}[\\text{QE event at } t+1 \\mid X_t],\n",
    "$$\n",
    "\n",
    "without requiring a specific functional form for $f(\\cdot)$.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Economic Meaning\n",
    "\n",
    "From an economic perspective:\n",
    "\n",
    "* The **Fed_Growth** variable remains the strongest predictor—confirming that expansionary balance sheet movements are precursors to future QE.\n",
    "* The **interaction with volatility** (captured implicitly by the RF) shows that the Fed's response to financial stress is **state-dependent**.\n",
    "* The higher predictive power of RF thus reveals that QE actions are not triggered by single linear thresholds but by **conditional relationships** between market stress and prior policy expansion.\n",
    "\n",
    "---\n",
    "\n",
    "**In summary**, the Random Forest extends the logistic model by allowing flexible, data-driven mapping from economic indicators to QE outcomes. Its superior performance—accuracy 0.77 vs. 0.73, AUC 0.85 vs. ~0.75—demonstrates that nonlinear dependencies play a crucial role in explaining the timing and likelihood of Federal Reserve quantitative easing actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98499ba7-a40e-4161-998d-b402eea8b53e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210914e4-f462-4842-b1b4-c4f069990eb1",
   "metadata": {},
   "source": [
    "# SECOND PART (ANDREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb163e0c-ce9b-4208-b9e7-a51e23fcd2a1",
   "metadata": {},
   "source": [
    "<# QE Prediction — **Expanded Python Model** (Handbook Draft)\n",
    "\n",
    "> **Purpose.** This document explains the **extended QE prediction pipeline** implemented in Python (`qe_expanded_daily_to_quarterly.py`). It covers the data sources, feature engineering from **daily** to **quarterly** frequency, target definition, model design (Random Forest, XGBoost), training/validation, outputs, and extensions. Math is included for clarity and reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Overview\n",
    "\n",
    "* **Research question.** How can **nonlinear interactions** between **financial stress**, **monetary stance**, and **macro expectations** improve forecasts of **QE in the next quarter**?\n",
    "* **Approach.** Build a **richer feature set** from daily FRED series → aggregate to quarterly → estimate\n",
    "  $$\n",
    "  P(\\text{QE}_{t+1} = 1 \\mid X_t)\n",
    "  $$\n",
    "  using **Random Forest** and **XGBoost**, then compare against a logistic baseline.\n",
    "* **Why Python?** Easy programmatic access to FRED, flexible data wrangling, and robust ML ecosystem.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Data: Sources and Series\n",
    "\n",
    "**Provider:** FRED (Federal Reserve Economic Data) via `fredapi`.\n",
    "\n",
    "**Series (daily calendar with forward-fill):**\n",
    "\n",
    "* **Policy & liquidity:** `WSHOSHO` (Fed securities), `M2SL` (M2), `FEDFUNDS` (eff. fed funds)\n",
    "* **Rates & spreads:** `GS10` (10Y Treasury), `BAA10Y` (BAA–10Y spread)\n",
    "* **Market stress:** `VIXCLS` (VIX)\n",
    "* **Macro:** `UNRATE` (unemployment), `INDPRO` (industrial production), `CPIAUCSL` (CPI), `T5YIFR` (5y5y inflation expectations)\n",
    "\n",
    "**Daily index construction.** For each series $S$, create a common daily index, join all series, **forward-fill** ($\\text{ffill}$) and **back-fill** ($\\text{bfill}$):\n",
    "$$\n",
    "S_d = \\text{FFILL}(\\text{BFILL}(S))\n",
    "$$\n",
    "This yields a synchronized daily panel $D$ across all series.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Feature Engineering (Daily → Quarterly)\n",
    "\n",
    "### 3.1 Quarter Label\n",
    "\n",
    "For each day $d$, assign quarter $q(d)$ and map to the quarter **end** timestamp. Group by quarter to compute aggregations.\n",
    "\n",
    "### 3.2 Quarter-End Levels (last observation in quarter)\n",
    "\n",
    "For a variable $Z$,\n",
    "$$\n",
    "Z^{\\text{level}}_t = Z_{\\text{last day of quarter } t}\n",
    "$$\n",
    "\n",
    "### 3.3 Within-Quarter Growth (first → last)\n",
    "\n",
    "For a variable $Z$,\n",
    "$$\n",
    "Z^{\\text{growth}}_t = 100 \\times \\left(\\frac{Z^{\\text{last}}_t}{Z^{\\text{first}}_t} - 1\\right)\n",
    "$$\n",
    "\n",
    "**Applied to:** Fed securities, M2, INDPRO, CPI.\n",
    "\n",
    "### 3.4 Realized Volatility (std of daily returns in quarter)\n",
    "\n",
    "For a daily return series $r_d$ inside quarter $t$,\n",
    "$$\n",
    "\\text{RV}(Z)_t = \\sqrt{\\frac{1}{n_t-1} \\sum_{d \\in t}\\left(r_d - \\bar{r}_t\\right)^2}\n",
    "\\quad\\text{with}\\quad\n",
    "r_d = 100 \\times \\left(\\frac{Z_d}{Z_{d-1}} - 1\\right)\n",
    "$$\n",
    "\n",
    "**Applied to:** VIX, M2, INDPRO.\n",
    "\n",
    "### 3.5 Extremes and Slope\n",
    "\n",
    "* **VIX extremes:** $\\text{VIX}^{\\max}_t$, $\\text{VIX}^{\\min}_t$\n",
    "* **Yield curve slope:** $\\text{Rate_Slope}_t = \\text{GS10}^{\\text{last}}_t - \\text{FEDFUNDS}^{\\text{last}}_t$\n",
    "\n",
    "### 3.6 Lags and Flags\n",
    "\n",
    "* **Lags:** For selected features $Z$: $Z_{t-1}$ (e.g., $\\text{Fed_Growth}_{t-1}$, $\\text{M2_Growth}_{t-1}$, $\\text{Rate_Slope}_{t-1}$)\n",
    "* **Binary flags (regime markers):**\n",
    "\n",
    "  * $\\text{VIX_High}_t = \\mathbb{1}[\\text{VIX}^{\\text{level}}_t > 30]$\n",
    "  * $\\text{High_Spread}_t = \\mathbb{1}[\\text{BAA10Y}^{\\text{level}}_t > 2]$\n",
    "  * $\\text{High_InflExp}_t = \\mathbb{1}[\\text{T5YIFR}^{\\text{level}}_t > 2.5]$\n",
    "\n",
    "### 3.7 Final Quarterly Feature Vector\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "X_t = [&\n",
    "\\underbrace{\\text{Fed_Securities}_t,\\ \\text{M2}_t,\\ \\text{FedFunds}_t,\\ \\text{GS10}_t,\\ \\text{BAA10Y}_t,\\ \\text{VIXCLS}_t,\\ \\text{UNRATE}_t,\\ \\text{INDPRO}_t,\\ \\text{CPIAUCSL}_t,\\ \\text{T5YIFR}_t}_{\\text{levels}},\\\\\n",
    "&\\underbrace{\\text{Fed_Growth}_t,\\ \\text{M2_Growth}_t,\\ \\text{INDPRO_Growth}_t,\\ \\text{CPI_Growth}_t}_{\\text{within-quarter growth}},\\\\\n",
    "&\\underbrace{\\text{VIX_realized_vol}_t,\\ \\text{M2_realized_vol}_t,\\ \\text{INDPRO_realized_vol}_t}_{\\text{realized vol}},\\\\\n",
    "&\\underbrace{\\text{VIX_max}_t,\\ \\text{VIX_min}_t,\\ \\text{Rate_Slope}_t}_{\\text{extremes & slope}},\\\\\n",
    "&\\underbrace{\\text{Fed_Growth_L1}_t,\\ \\text{M2_Growth_L1}_t,\\ \\text{INDPRO_Growth_L1}_t,\\ \\text{Rate_Slope_L1}_t}_{\\text{lags}},\\\\\n",
    "&\\underbrace{\\text{VIX_High}_t,\\ \\text{High_Spread}_t,\\ \\text{High_InflExp}_t}_{\\text{flags}}\n",
    "]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Target: QE in the Next Quarter\n",
    "\n",
    "Binary indicator of **significant** balance sheet expansion:\n",
    "\n",
    "$$\n",
    "\\text{QE}_{t+1} =\n",
    "\\begin{cases}\n",
    "1, & \\text{if } \\text{Fed_Securities}_{t+1} - \\text{Fed_Securities}_t > 100\\text{ B+},\\\\\n",
    "0, & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This operationalizes \"QE activity\" as $\\$100\\text{B+}$ quarter-over-quarter growth in securities holdings.\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Model Framework\n",
    "\n",
    "### 5.1 Problem Statement\n",
    "\n",
    "Estimate\n",
    "$$\n",
    "P(\\text{QE}_{t+1}=1 \\mid X_t)\n",
    "$$\n",
    "with models that **capture nonlinearities** and **interactions** missed by a linear logit.\n",
    "\n",
    "### 5.2 Random Forest (RF)\n",
    "\n",
    "**Estimator**\n",
    "$$\n",
    "f_{\\text{RF}}(X_t) = \\frac{1}{B}\\sum_{b=1}^{B} T_b(X_t)\n",
    "$$\n",
    "\n",
    "* $T_b$: individual decision tree\n",
    "* $B$: number of trees (here, $B=500$)\n",
    "\n",
    "**Key training settings**\n",
    "\n",
    "* `n_estimators=500`\n",
    "* `max_features ≈ sqrt(p)` (p = number of features)\n",
    "* `class_weight='balanced'` (handle class skew)\n",
    "* **Output:** class probability = average of tree votes.\n",
    "\n",
    "**What it buys us.** Low-variance nonlinear learner; detects **thresholds** and **joint conditions** (e.g., high VIX **and** steepening/flattening slope) with **minimal tuning**.\n",
    "\n",
    "### 5.3 XGBoost (XGB)\n",
    "\n",
    "**Objective and regularization**\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{i} l\\big(y_i, \\hat{y}_i\\big) + \\sum_{k}\\Omega(f_k),\n",
    "\\quad\n",
    "\\Omega(f_k) = \\gamma T + \\frac{1}{2}\\lambda \\|w\\|^2\n",
    "$$\n",
    "\n",
    "* $l$: log-loss for binary classification\n",
    "* Trees $f_k$ are added **sequentially** to correct residuals\n",
    "* $\\gamma, \\lambda$: control tree complexity (regularization)\n",
    "\n",
    "**Key training settings**\n",
    "\n",
    "* `learning_rate=0.05`, `max_depth=4`, `subsample=0.8`, `colsample_bytree=0.8`\n",
    "* `n_estimators=400`, `min_child_weight=3`, `reg_lambda=1.0`\n",
    "* `scale_pos_weight = \\frac{\\#\\text{neg}}{\\#\\text{pos}}` (class imbalance adjustment)\n",
    "\n",
    "**What it buys us.** **High-bias/high-control** additive trees with explicit regularization; often **state-of-the-art** with sufficient data.\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Train/Test Protocol\n",
    "\n",
    "* **Temporal split:** first **70%** of quarters for training, last **30%** for testing (prevents look-ahead).\n",
    "* **Feature target matrix:**\n",
    "  $X_{\\text{train}}, y_{\\text{train}}$ from early quarters,\n",
    "  $X_{\\text{test}}, y_{\\text{test}}$ from later quarters.\n",
    "* **Metrics:** Accuracy, ROC AUC, confusion matrix, classification report; ROC curves saved to PNG.\n",
    "\n",
    "**Artifacts saved (to `../../data`):**\n",
    "\n",
    "* `expanded_daily_all.csv` — daily merged data\n",
    "* `expanded_quarterly_features_py.csv` — engineered quarterly features\n",
    "* `model_comparison_py.csv` — RF vs XGB metrics\n",
    "* `rf_feature_importance_py.csv`, `xgb_feature_importance_py.csv` — importances\n",
    "* `roc_expanded_model_py.png` — ROC overlay plot\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Reading and Communicating Results\n",
    "\n",
    "> **Example (from your runs):** RF beats logistic on AUC/accuracy; XGB competitive but can underperform on **small sample** quarterly panels.\n",
    "\n",
    "* **Interpretation:** RF's gain indicates **nonlinear**, **interaction-driven** policy behavior.\n",
    "* **Feature importance (typical):** Fed-related growth (policy momentum), VIX realized volatility, rate slope, and M2 growth/volatility rank highly.\n",
    "* **ROC curve:** RF above baseline logit; XGB varies with sample size and tuning.\n",
    "\n",
    "> **Recommended table set (for slides):**\n",
    "\n",
    "* Table 1 — Target distribution (Non-QE vs QE counts)\n",
    "* Table 2 — RF performance (Accuracy, AUC, Sens., Spec., Kappa, OOB error)\n",
    "* Table 3 — Logistic coefficients (with p-values)\n",
    "* Table 4 — Model comparison (RF vs XGB: Accuracy & AUC)\n",
    "\n",
    "---\n",
    "\n",
    "## 8) Why the Extended Feature Set Helps\n",
    "\n",
    "* **Monetary stance** (Fed securities, M2) + **market stress** (VIX, spreads) + **macro** (INDPRO, CPI, UNRATE) + **expectations** (T5YIFR)\n",
    "  ⇒ delivers **orthogonal signals** about policy context.\n",
    "* **Realized vol** & **extremes** add **distributional information**; **lags** capture **persistence**.\n",
    "* ML models on this richer $X_t$ learn **state-dependent rules**: e.g., QE probability rises when volatility increases **and** real activity weakens **under a flat curve**.\n",
    "\n",
    "---\n",
    "\n",
    "## 9) Robustness & Best Practices\n",
    "\n",
    "* **Time-aware validation:** keep chronological splits; optionally add **rolling-origin** backtests.\n",
    "* **Class balance:** use `class_weight='balanced'` (RF) and `scale_pos_weight` (XGB).\n",
    "* **Leakage checks:** ensure no forward-looking fields; the target uses $t$ and $t+1$ only.\n",
    "* **Sensitivity analyses:** thresholds (e.g., $\\$100\\text{B}$ → alternative cutoffs), re-sample windows (pre/post-GFC, COVID), alternative spreads (e.g., term premium).\n",
    "* **Calibration:** post-hoc Platt or isotonic for probability calibration if you use probabilities in downstream decisions.\n",
    "* **Stability:** compare **feature importances** and **partial dependence** across subsamples.\n",
    "\n",
    "---\n",
    "\n",
    "## 10) Extensions\n",
    "\n",
    "* **New features:** Financial Conditions Indices, term premium estimates, liquidity/credit ETFs (if allowed), Treasury volatility (MOVE), equity drawdown metrics.\n",
    "* **Temporal models:** Sequence learners (LSTM/Temporal CNN) treating quarters as ordered sequences.\n",
    "* **Multi-horizon targets:** $\\text{QE}_{t+h}$ for $h\\in\\{1,2\\}$ quarters ahead; **multilabel** for QE intensity.\n",
    "* **Structural overlays:** Combine ML with interpretable **reaction-function priors** (e.g., generalized additive models) for semi-parametric inference.\n",
    "\n",
    "---\n",
    "\n",
    "## 11) Reproducibility Checklist\n",
    "\n",
    "* **Environment:**\n",
    "  `pip install pandas numpy matplotlib scikit-learn xgboost fredapi pyarrow`\n",
    "* **Secrets:** set `FRED_API_KEY` (as in the script).\n",
    "* **Run:** `python qe_expanded_daily_to_quarterly.py`\n",
    "* **Verify outputs:** quarterly CSV, model comparison CSV, ROC PNG, importances CSVs.\n",
    "* **Version control:** commit script + lockfile; tag runs with date and git hash.\n",
    "\n",
    "---\n",
    "\n",
    "## 12) Quick \"How it Works\" (ASCII Pipeline)\n",
    "\n",
    "```\n",
    "FRED series (daily) ──> merge daily panel ──> ffill/bfill ──> add quarter labels\n",
    "                                │\n",
    "                                └─> within-quarter growth, realized vol, extremes, lags, flags\n",
    "                                                      │\n",
    "                                    ─────────> quarterly feature set $X_t$\n",
    "                                                      │\n",
    "                                               target $\\text{QE}_{t+1}$\n",
    "                                                      │\n",
    "                           time split (70/30) ──> RF & XGB ──> metrics + plots + CSV artifacts\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 13) Mathematical Summary (At-a-Glance)\n",
    "\n",
    "* **Goal**\n",
    "  $$\n",
    "  \\text{Predict } P(\\text{QE}_{t+1}=1 \\mid X_t)\n",
    "  $$\n",
    "* **Target**\n",
    "  $$\n",
    "  \\text{QE}_{t+1} = \\mathbb{1}\\big[\\text{Fed_Securities}_{t+1}-\\text{Fed_Securities}_t > \\$100\\text{B}\\big]\n",
    "  $$\n",
    "* **RF**\n",
    "  $$\n",
    "  f_{\\text{RF}}(X_t) = \\frac{1}{B}\\sum_{b=1}^{B} T_b(X_t)\n",
    "  $$\n",
    "* **XGB**\n",
    "  $$\n",
    "  \\mathcal{L} = \\sum_{i} l(y_i, \\hat{y}_i) + \\sum_k \\big(\\gamma T_k + \\tfrac{1}{2}\\lambda \\|w_k\\|^2\\big)\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "### Final Takeaway\n",
    "\n",
    "The **extended feature engineering** transforms rich, high-frequency macro-financial data into informative quarterly signals. **Random Forest** and **XGBoost** then uncover **nonlinear, state-dependent** patterns linking policy behavior and market stress to future QE. In practice, RF tends to be **robust on small quarterly samples** with minimal tuning, while XGB benefits from **careful regularization** and **more data**; both **outperform linear benchmarks** when the QE regime is interaction-driven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61159462-1bd1-4710-a610-c458da30860a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd194faf-061d-4108-9169-d51f7b296ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4d5f6-a4b9-44e6-85cc-68ecada9101c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee997de-9f0b-4806-8647-cd3608ddac56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b3ff2-b41e-4c6d-a5d7-dd8c38e36bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39b36e-1483-4d6e-b4a5-7ef022e7a0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668f473-e41f-4f96-9a4a-b5ce070e8689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53619a23-2e57-408c-8132-403b8e80bc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c31a1-f013-4deb-a2f3-6c60a0add824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1aac0-0267-479d-a816-3bcf58d3e8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed969e6-12ce-4bb5-8aa7-9d00fd0ccedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d315a1-30d7-4498-b77a-6b13de760465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d2d272-2c94-47bb-b1ac-2ee44b503275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba0bc15-ae7b-4e93-bcdb-5b615b39ddc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f69832e-2332-4dd5-af9c-e0067e13d12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15fb98e-9753-4752-87ed-e543f538cc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079ae81-d55e-4ca8-8445-74ab94977101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
